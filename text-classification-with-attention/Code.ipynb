{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hymLicJTeCEP",
        "ZL7JAhv3BnUc",
        "qboe-nwyBhmz",
        "olF2OwuGawDG",
        "nIWpLxtyJcWo"
      ],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#libraries"
      ],
      "metadata": {
        "id": "hymLicJTeCEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data manipulation and preprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split, ParameterGrid\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# TensorFlow and Keras imports for model building\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Attention, Dense, Dropout, Concatenate, Input, Flatten, Reshape\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Data visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# File and directory management\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Kaggle related functionality\n",
        "import kagglehub\n"
      ],
      "metadata": {
        "id": "V-fMLEQPeBVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#downlod_imdb"
      ],
      "metadata": {
        "id": "ZL7JAhv3BnUc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85f_-k_C-G2S",
        "outputId": "e1ef370c-29c2-4ad3-fb4c-3a3c242d1431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25.7M/25.7M [00:00<00:00, 61.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1\n"
          ]
        }
      ],
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_path = \"/content/imdb_dataset\"\n",
        "os.makedirs(new_path, exist_ok=True)\n",
        "shutil.move(path, new_path)"
      ],
      "metadata": {
        "id": "AWjd2jU--7ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = os.path.join(\"/content/imdb_dataset/1/IMDB Dataset.csv\")  # یا نام فایل را جایگزین کنید\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# نمایش چند ردیف ابتدایی\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTNNM7Ur_Muz",
        "outputId": "94b8982f-9e65-4059-c449-6c28d28bd81f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#data_analys"
      ],
      "metadata": {
        "id": "ct6ssntkBbtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()\n",
        "print(f\"New shape after removing duplicates: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESNK7CtRCTC7",
        "outputId": "a9af15da-90a4-41d6-b30f-487e08984246"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New shape after removing duplicates: (49582, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# نمایش اطلاعات کلی دیتاست\n",
        "print(\"Dataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "# نمایش تعداد نمونه‌ها و ستون‌ها\n",
        "print(f\"Shape of dataset: {df.shape}\")\n",
        "\n",
        "# نمایش نام ستون‌ها\n",
        "print(\"Columns:\", df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JB1Ot5uA5y4",
        "outputId": "c7a5fcbc-40cd-4d1a-b90f-7bf3267a3fc3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 49582 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     49582 non-null  object\n",
            " 1   sentiment  49582 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.1+ MB\n",
            "None\n",
            "Shape of dataset: (49582, 2)\n",
            "Columns: Index(['review', 'sentiment'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Category distribution:\")\n",
        "print(df['sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1CyvWwFBBjA",
        "outputId": "549c7315-1ce5-4058-f410-258a41f36e16"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category distribution:\n",
            "sentiment\n",
            "positive    24884\n",
            "negative    24698\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text_length'] = df['review'].apply(len)\n",
        "print(\"Text length statistics:\")\n",
        "print(df['text_length'].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji2rWJJ-BETS",
        "outputId": "537dd398-a325-4a42-f2d5-6a2e7d8cf4a6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text length statistics:\n",
            "count    49582.000000\n",
            "mean      1310.568230\n",
            "std        990.762238\n",
            "min         32.000000\n",
            "25%        699.000000\n",
            "50%        971.000000\n",
            "75%       1592.000000\n",
            "max      13704.000000\n",
            "Name: text_length, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = df.duplicated().sum()\n",
        "print(f\"Number of duplicate rows: {duplicates}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jii__Lh2BJyn",
        "outputId": "b77aac51-d97b-4858-e83c-95ce4d065a73"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicate rows: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing values in each column:\")\n",
        "print(missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTgaWLR1BNVY",
        "outputId": "678e52c6-ee55-45a5-f9d7-12ebce551b8d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in each column:\n",
            "review         0\n",
            "sentiment      0\n",
            "text_length    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sns.countplot(x='sentiment', data=df)\n",
        "plt.title(\"Distribution of Sentiment\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "QN5lhWN_BQ7s",
        "outputId": "90469f04-fae0-4235-a029-0d5139f53c0f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#preprpcess"
      ],
      "metadata": {
        "id": "qboe-nwyBhmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# دانلود منابع NLTK\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# تعریف تابع پیش‌پردازش\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # تبدیل به حروف کوچک\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # حذف علائم نگارشی\n",
        "    words = text.split()  # تقسیم متن به کلمات\n",
        "    words = [word for word in words if word not in stop_words]  # حذف کلمات بی‌معنی\n",
        "    return ' '.join(words)\n",
        "\n",
        "# پیش‌پردازش داده‌ها\n",
        "df['processed_review'] = df['review'].apply(preprocess_text)\n",
        "\n",
        "# نمایش چند نمونه\n",
        "print(df['processed_review'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHlz_oyfBk-F",
        "outputId": "0066eb66-bbb4-4986-9766-062486db6bdb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    one reviewers mentioned watching 1 oz episode ...\n",
            "1    wonderful little production br br filming tech...\n",
            "2    thought wonderful way spend time hot summer we...\n",
            "3    basically theres family little boy jake thinks...\n",
            "4    petter matteis love time money visually stunni...\n",
            "Name: processed_review, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تقسیم داده‌ها به آموزش و تست (80% آموزش، 20% تست)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_review'], df['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# تقسیم داده‌های آموزش به آموزش و اعتبارسنجی (80% آموزش، 20% اعتبارسنجی)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training data: {len(X_train)} samples\")\n",
        "print(f\"Validation data: {len(X_val)} samples\")\n",
        "print(f\"Test data: {len(X_test)} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0tvdF7tJMzx",
        "outputId": "3fc50cdf-a9fc-4bf8-f706-54f060a613f5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data: 31732 samples\n",
            "Validation data: 7933 samples\n",
            "Test data: 9917 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# استفاده از Tokenizer برای توکن‌سازی داده‌ها\n",
        "tokenizer = Tokenizer(num_words=10000)  # حداکثر 10000 کلمه پرتکرار\n",
        "tokenizer.fit_on_texts(X_train)  # آموزش توکنایزر روی داده‌های آموزشی\n",
        "\n",
        "# تبدیل متن‌ها به توکن‌های عددی\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# پدینگ توکن‌ها برای یکسان کردن طول آنها\n",
        "max_len = 200  # حداکثر طول هر متن (می‌توانید این مقدار را تغییر دهید)\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_val_pad = pad_sequences(X_val_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "print(f\"Shape of padded training data: {X_train_pad.shape}\")\n",
        "print(f\"Shape of padded validation data: {X_val_pad.shape}\")\n",
        "print(f\"Shape of padded test data: {X_test_pad.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgGmfGL7JQH6",
        "outputId": "40e2c3cb-eff1-4c53-f37b-d1417b610628"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of padded training data: (31732, 200)\n",
            "Shape of padded validation data: (7933, 200)\n",
            "Shape of padded test data: (9917, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تبدیل برچسب‌ها به عددی\n",
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_val = encoder.transform(y_val)\n",
        "y_test = encoder.transform(y_test)"
      ],
      "metadata": {
        "id": "o5ZPd_39KAoG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparamet"
      ],
      "metadata": {
        "id": "olF2OwuGawDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# تابع برای ساخت مدل\n",
        "def create_model(num_layers=1, learning_rate=0.001, dropout_rate=0.5):\n",
        "    inputs = Input(shape=(max_len,))\n",
        "    x = Embedding(input_dim=10000, output_dim=128, input_length=max_len)(inputs)\n",
        "\n",
        "    for _ in range(num_layers):\n",
        "        x_lstm = LSTM(128, return_sequences=True)(x)\n",
        "        attention_output = Attention()([x_lstm, x_lstm])\n",
        "        x = Concatenate()([x_lstm, attention_output])\n",
        "\n",
        "    x = LSTM(128)(x)\n",
        "    x = Dropout(dropout_rate)(x)  # Dropout for regularization\n",
        "    x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, x)\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# پارامترهای مختلف برای تست\n",
        "param_grid = {\n",
        "    'num_layers': [1, 2, 3],  # تعداد لایه‌ها\n",
        "    'learning_rate': [0.0001, 0.001, 0.01],  # نرخ یادگیری\n",
        "    'dropout_rate': [0.3, 0.5, 0.7],  # درصد Dropout\n",
        "}\n",
        "\n",
        "# تعریف EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# تبدیل داده‌ها به tf.data.Dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_pad, y_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val_pad, y_val))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_pad, y_test))\n",
        "\n",
        "# استفاده از 10 درصد داده‌ها برای آموزش\n",
        "train_dataset = train_dataset.take(int(0.1 * len(X_train)))\n",
        "\n",
        "# جستجوی پارامترهای مختلف\n",
        "best_acc = 0\n",
        "best_params = None\n",
        "\n",
        "# انجام Grid Search\n",
        "for params in ParameterGrid(param_grid):\n",
        "    print(f\"Training with params: {params}\")\n",
        "\n",
        "    # ایجاد مدل با پارامترهای مختلف\n",
        "    model = create_model(num_layers=params['num_layers'], learning_rate=params['learning_rate'], dropout_rate=params['dropout_rate'])\n",
        "\n",
        "    # آموزش مدل\n",
        "    history = model.fit(\n",
        "        train_dataset.batch(64), epochs=5, validation_data=val_dataset.batch(64),\n",
        "        callbacks=[early_stopping], verbose=1\n",
        "    )\n",
        "\n",
        "    # ارزیابی مدل روی داده‌های تست\n",
        "    test_loss, test_acc = model.evaluate(test_dataset.batch(64))\n",
        "    print(f\"Test accuracy for {params}: {test_acc}\")\n",
        "\n",
        "    # انتخاب بهترین مدل بر اساس دقت\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        best_params = params\n",
        "\n",
        "# نمایش بهترین پارامترها و دقت\n",
        "print(f\"Best accuracy: {best_acc}\")\n",
        "print(f\"Best parameters: {best_params}\")\n"
      ],
      "metadata": {
        "id": "4sonantUn3HR",
        "outputId": "b7d0ac18-5ba6-4f9f-80aa-4e5ba08c6532",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with params: {'dropout_rate': 0.3, 'learning_rate': 0.0001, 'num_layers': 1}\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 3s/step - accuracy: 0.5087 - loss: 0.6924 - val_accuracy: 0.5067 - val_loss: 0.6928\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 2s/step - accuracy: 0.5357 - loss: 0.6894 - val_accuracy: 0.5746 - val_loss: 0.6830\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 2s/step - accuracy: 0.6818 - loss: 0.6223 - val_accuracy: 0.7728 - val_loss: 0.4601\n",
            "Epoch 4/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 2s/step - accuracy: 0.8660 - loss: 0.3391 - val_accuracy: 0.8197 - val_loss: 0.4141\n",
            "Epoch 5/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2s/step - accuracy: 0.9263 - loss: 0.1899 - val_accuracy: 0.8257 - val_loss: 0.4213\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 398ms/step - accuracy: 0.8153 - loss: 0.4105\n",
            "Test accuracy for {'dropout_rate': 0.3, 'learning_rate': 0.0001, 'num_layers': 1}: 0.8131491541862488\n",
            "Training with params: {'dropout_rate': 0.3, 'learning_rate': 0.0001, 'num_layers': 2}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 4s/step - accuracy: 0.5200 - loss: 0.6926 - val_accuracy: 0.5175 - val_loss: 0.6927\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 4s/step - accuracy: 0.5556 - loss: 0.6870 - val_accuracy: 0.7528 - val_loss: 0.5622\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 4s/step - accuracy: 0.7945 - loss: 0.4671 - val_accuracy: 0.8041 - val_loss: 0.4382\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 643ms/step - accuracy: 0.5168 - loss: 0.6929\n",
            "Test accuracy for {'dropout_rate': 0.3, 'learning_rate': 0.0001, 'num_layers': 2}: 0.5161843299865723\n",
            "Training with params: {'dropout_rate': 0.3, 'learning_rate': 0.0001, 'num_layers': 3}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 6s/step - accuracy: 0.5106 - loss: 0.6929 - val_accuracy: 0.5038 - val_loss: 0.6929\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 5s/step - accuracy: 0.5523 - loss: 0.6880 - val_accuracy: 0.7410 - val_loss: 0.5587\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 5s/step - accuracy: 0.8064 - loss: 0.4392 - val_accuracy: 0.7792 - val_loss: 0.4697\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 900ms/step - accuracy: 0.5024 - loss: 0.6930\n",
            "Test accuracy for {'dropout_rate': 0.3, 'learning_rate': 0.0001, 'num_layers': 3}: 0.5044872164726257\n",
            "Training with params: {'dropout_rate': 0.3, 'learning_rate': 0.001, 'num_layers': 1}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 2s/step - accuracy: 0.5829 - loss: 0.6637 - val_accuracy: 0.7556 - val_loss: 0.5118\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 2s/step - accuracy: 0.8918 - loss: 0.2994 - val_accuracy: 0.8100 - val_loss: 0.4442\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 3s/step - accuracy: 0.9667 - loss: 0.1080 - val_accuracy: 0.8057 - val_loss: 0.6593\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 428ms/step - accuracy: 0.7570 - loss: 0.5142\n",
            "Test accuracy for {'dropout_rate': 0.3, 'learning_rate': 0.001, 'num_layers': 1}: 0.7581930160522461\n",
            "Training with params: {'dropout_rate': 0.3, 'learning_rate': 0.001, 'num_layers': 2}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 4s/step - accuracy: 0.5518 - loss: 0.6756 - val_accuracy: 0.4968 - val_loss: 0.7040\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 4s/step - accuracy: 0.5224 - loss: 0.6905 - val_accuracy: 0.4950 - val_loss: 0.6863\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 4s/step - accuracy: 0.5147 - loss: 0.6915 - val_accuracy: 0.4958 - val_loss: 0.6892\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 660ms/step - accuracy: 0.5048 - loss: 0.7014\n",
            "Test accuracy for {'dropout_rate': 0.3, 'learning_rate': 0.001, 'num_layers': 2}: 0.5029746890068054\n",
            "Training with params: {'dropout_rate': 0.3, 'learning_rate': 0.001, 'num_layers': 3}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 6s/step - accuracy: 0.5455 - loss: 0.6835 - val_accuracy: 0.7880 - val_loss: 0.4772\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 5s/step - accuracy: 0.8671 - loss: 0.3386 - val_accuracy: 0.7988 - val_loss: 0.5029\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 5s/step - accuracy: 0.9728 - loss: 0.0930 - val_accuracy: 0.7699 - val_loss: 0.5199\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 879ms/step - accuracy: 0.7805 - loss: 0.4807\n",
            "Test accuracy for {'dropout_rate': 0.3, 'learning_rate': 0.001, 'num_layers': 3}: 0.778461217880249\n",
            "Training with params: {'dropout_rate': 0.3, 'learning_rate': 0.01, 'num_layers': 1}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.5976 - loss: 0.6992 - val_accuracy: 0.6931 - val_loss: 0.6225\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2s/step - accuracy: 0.8030 - loss: 0.4762 - val_accuracy: 0.6752 - val_loss: 0.6244\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 2s/step - accuracy: 0.8498 - loss: 0.4020 - val_accuracy: 0.7688 - val_loss: 0.5007\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 410ms/step - accuracy: 0.6890 - loss: 0.6230\n",
            "Test accuracy for {'dropout_rate': 0.3, 'learning_rate': 0.01, 'num_layers': 1}: 0.6874054670333862\n",
            "Training with params: {'dropout_rate': 0.3, 'learning_rate': 0.01, 'num_layers': 2}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 4s/step - accuracy: 0.5028 - loss: 0.7798 - val_accuracy: 0.4959 - val_loss: 0.6957\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 4s/step - accuracy: 0.5137 - loss: 0.6919 - val_accuracy: 0.4959 - val_loss: 0.6941\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 4s/step - accuracy: 0.4946 - loss: 0.6975 - val_accuracy: 0.4959 - val_loss: 0.6942\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 642ms/step - accuracy: 0.5023 - loss: 0.6949\n",
            "Test accuracy for {'dropout_rate': 0.3, 'learning_rate': 0.01, 'num_layers': 2}: 0.5019662976264954\n",
            "Training with params: {'dropout_rate': 0.3, 'learning_rate': 0.01, 'num_layers': 3}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 5s/step - accuracy: 0.4625 - loss: 0.8412 - val_accuracy: 0.4959 - val_loss: 0.6938\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 6s/step - accuracy: 0.5175 - loss: 0.6938 - val_accuracy: 0.4959 - val_loss: 0.6948\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 5s/step - accuracy: 0.5120 - loss: 0.6940 - val_accuracy: 0.4959 - val_loss: 0.6942\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 876ms/step - accuracy: 0.5023 - loss: 0.6935\n",
            "Test accuracy for {'dropout_rate': 0.3, 'learning_rate': 0.01, 'num_layers': 3}: 0.5019662976264954\n",
            "Training with params: {'dropout_rate': 0.5, 'learning_rate': 0.0001, 'num_layers': 1}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.5045 - loss: 0.6926 - val_accuracy: 0.5177 - val_loss: 0.6925\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 2s/step - accuracy: 0.5417 - loss: 0.6894 - val_accuracy: 0.5567 - val_loss: 0.6839\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 2s/step - accuracy: 0.6660 - loss: 0.6256 - val_accuracy: 0.7918 - val_loss: 0.4470\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 410ms/step - accuracy: 0.5120 - loss: 0.6926\n",
            "Test accuracy for {'dropout_rate': 0.5, 'learning_rate': 0.0001, 'num_layers': 1}: 0.5141676068305969\n",
            "Training with params: {'dropout_rate': 0.5, 'learning_rate': 0.0001, 'num_layers': 2}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 4s/step - accuracy: 0.5180 - loss: 0.6921 - val_accuracy: 0.5154 - val_loss: 0.6930\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 4s/step - accuracy: 0.5428 - loss: 0.6893 - val_accuracy: 0.5463 - val_loss: 0.6838\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 4s/step - accuracy: 0.6648 - loss: 0.6247 - val_accuracy: 0.7752 - val_loss: 0.4808\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 668ms/step - accuracy: 0.5121 - loss: 0.6933\n",
            "Test accuracy for {'dropout_rate': 0.5, 'learning_rate': 0.0001, 'num_layers': 2}: 0.5127558708190918\n",
            "Training with params: {'dropout_rate': 0.5, 'learning_rate': 0.0001, 'num_layers': 3}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 5s/step - accuracy: 0.5049 - loss: 0.6928 - val_accuracy: 0.5030 - val_loss: 0.6926\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 5s/step - accuracy: 0.5600 - loss: 0.6861 - val_accuracy: 0.6878 - val_loss: 0.5713\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 5s/step - accuracy: 0.7793 - loss: 0.4570 - val_accuracy: 0.8045 - val_loss: 0.4636\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 879ms/step - accuracy: 0.4970 - loss: 0.6929\n",
            "Test accuracy for {'dropout_rate': 0.5, 'learning_rate': 0.0001, 'num_layers': 3}: 0.500554621219635\n",
            "Training with params: {'dropout_rate': 0.5, 'learning_rate': 0.001, 'num_layers': 1}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 3s/step - accuracy: 0.5641 - loss: 0.6594 - val_accuracy: 0.8027 - val_loss: 0.4341\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 2s/step - accuracy: 0.8937 - loss: 0.2831 - val_accuracy: 0.8108 - val_loss: 0.5390\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 2s/step - accuracy: 0.9652 - loss: 0.0929 - val_accuracy: 0.8181 - val_loss: 0.5647\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 412ms/step - accuracy: 0.7935 - loss: 0.4377\n",
            "Test accuracy for {'dropout_rate': 0.5, 'learning_rate': 0.001, 'num_layers': 1}: 0.7936875820159912\n",
            "Training with params: {'dropout_rate': 0.5, 'learning_rate': 0.001, 'num_layers': 2}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 4s/step - accuracy: 0.5393 - loss: 0.6774 - val_accuracy: 0.6927 - val_loss: 0.6473\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 4s/step - accuracy: 0.8271 - loss: 0.4279 - val_accuracy: 0.7928 - val_loss: 0.5393\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 4s/step - accuracy: 0.9331 - loss: 0.1988 - val_accuracy: 0.7999 - val_loss: 0.6772\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 664ms/step - accuracy: 0.6921 - loss: 0.6486\n",
            "Test accuracy for {'dropout_rate': 0.5, 'learning_rate': 0.001, 'num_layers': 2}: 0.6942623853683472\n",
            "Training with params: {'dropout_rate': 0.5, 'learning_rate': 0.001, 'num_layers': 3}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 5s/step - accuracy: 0.5468 - loss: 0.6791 - val_accuracy: 0.7761 - val_loss: 0.4865\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 5s/step - accuracy: 0.8420 - loss: 0.3770 - val_accuracy: 0.7867 - val_loss: 0.5706\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 5s/step - accuracy: 0.9390 - loss: 0.1819 - val_accuracy: 0.7959 - val_loss: 0.6806\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 894ms/step - accuracy: 0.7719 - loss: 0.4924\n",
            "Test accuracy for {'dropout_rate': 0.5, 'learning_rate': 0.001, 'num_layers': 3}: 0.7701926231384277\n",
            "Training with params: {'dropout_rate': 0.5, 'learning_rate': 0.01, 'num_layers': 1}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.5825 - loss: 0.7007 - val_accuracy: 0.7900 - val_loss: 0.4762\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 3s/step - accuracy: 0.8415 - loss: 0.4005 - val_accuracy: 0.7749 - val_loss: 0.5809\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 3s/step - accuracy: 0.8895 - loss: 0.2833 - val_accuracy: 0.7862 - val_loss: 0.5713\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 420ms/step - accuracy: 0.7841 - loss: 0.4809\n",
            "Test accuracy for {'dropout_rate': 0.5, 'learning_rate': 0.01, 'num_layers': 1}: 0.7819905281066895\n",
            "Training with params: {'dropout_rate': 0.5, 'learning_rate': 0.01, 'num_layers': 2}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 4s/step - accuracy: 0.5222 - loss: 0.7788 - val_accuracy: 0.4915 - val_loss: 0.7008\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 4s/step - accuracy: 0.5281 - loss: 0.6987 - val_accuracy: 0.4959 - val_loss: 0.6964\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 4s/step - accuracy: 0.5004 - loss: 0.6968 - val_accuracy: 0.4959 - val_loss: 0.6951\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 644ms/step - accuracy: 0.4954 - loss: 0.6997\n",
            "Test accuracy for {'dropout_rate': 0.5, 'learning_rate': 0.01, 'num_layers': 2}: 0.49349603056907654\n",
            "Training with params: {'dropout_rate': 0.5, 'learning_rate': 0.01, 'num_layers': 3}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 5s/step - accuracy: 0.5002 - loss: 0.7713 - val_accuracy: 0.4959 - val_loss: 0.6949\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 6s/step - accuracy: 0.5065 - loss: 0.6960 - val_accuracy: 0.4959 - val_loss: 0.6948\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 5s/step - accuracy: 0.5083 - loss: 0.6948 - val_accuracy: 0.4959 - val_loss: 0.6949\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 892ms/step - accuracy: 0.5023 - loss: 0.6943\n",
            "Test accuracy for {'dropout_rate': 0.5, 'learning_rate': 0.01, 'num_layers': 3}: 0.5019662976264954\n",
            "Training with params: {'dropout_rate': 0.7, 'learning_rate': 0.0001, 'num_layers': 1}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.5055 - loss: 0.6927 - val_accuracy: 0.5094 - val_loss: 0.6924\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 3s/step - accuracy: 0.5434 - loss: 0.6897 - val_accuracy: 0.5393 - val_loss: 0.6876\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 2s/step - accuracy: 0.6370 - loss: 0.6540 - val_accuracy: 0.7900 - val_loss: 0.4502\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 414ms/step - accuracy: 0.5100 - loss: 0.6926\n",
            "Test accuracy for {'dropout_rate': 0.7, 'learning_rate': 0.0001, 'num_layers': 1}: 0.5105374455451965\n",
            "Training with params: {'dropout_rate': 0.7, 'learning_rate': 0.0001, 'num_layers': 2}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 4s/step - accuracy: 0.5076 - loss: 0.6928 - val_accuracy: 0.5086 - val_loss: 0.6929\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 4s/step - accuracy: 0.5355 - loss: 0.6913 - val_accuracy: 0.5510 - val_loss: 0.6857\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 4s/step - accuracy: 0.6620 - loss: 0.6250 - val_accuracy: 0.7962 - val_loss: 0.4421\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 643ms/step - accuracy: 0.5135 - loss: 0.6930\n",
            "Test accuracy for {'dropout_rate': 0.7, 'learning_rate': 0.0001, 'num_layers': 2}: 0.5119491815567017\n",
            "Training with params: {'dropout_rate': 0.7, 'learning_rate': 0.0001, 'num_layers': 3}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 6s/step - accuracy: 0.5109 - loss: 0.6928 - val_accuracy: 0.5061 - val_loss: 0.6932\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 6s/step - accuracy: 0.5456 - loss: 0.6906 - val_accuracy: 0.5355 - val_loss: 0.6880\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 5s/step - accuracy: 0.6429 - loss: 0.6440 - val_accuracy: 0.7812 - val_loss: 0.4736\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 886ms/step - accuracy: 0.5138 - loss: 0.6934\n",
            "Test accuracy for {'dropout_rate': 0.7, 'learning_rate': 0.0001, 'num_layers': 3}: 0.5122516751289368\n",
            "Training with params: {'dropout_rate': 0.7, 'learning_rate': 0.001, 'num_layers': 1}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.5449 - loss: 0.6794 - val_accuracy: 0.7567 - val_loss: 0.5318\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 2s/step - accuracy: 0.8258 - loss: 0.4303 - val_accuracy: 0.8189 - val_loss: 0.5100\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 2s/step - accuracy: 0.9385 - loss: 0.1729 - val_accuracy: 0.8039 - val_loss: 0.6293\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 420ms/step - accuracy: 0.7479 - loss: 0.5338\n",
            "Test accuracy for {'dropout_rate': 0.7, 'learning_rate': 0.001, 'num_layers': 1}: 0.7537561655044556\n",
            "Training with params: {'dropout_rate': 0.7, 'learning_rate': 0.001, 'num_layers': 2}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 4s/step - accuracy: 0.5532 - loss: 0.6739 - val_accuracy: 0.7751 - val_loss: 0.4723\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 4s/step - accuracy: 0.8779 - loss: 0.3231 - val_accuracy: 0.7950 - val_loss: 0.5097\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 4s/step - accuracy: 0.9586 - loss: 0.1202 - val_accuracy: 0.8055 - val_loss: 0.7726\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 667ms/step - accuracy: 0.7728 - loss: 0.4753\n",
            "Test accuracy for {'dropout_rate': 0.7, 'learning_rate': 0.001, 'num_layers': 2}: 0.7757386565208435\n",
            "Training with params: {'dropout_rate': 0.7, 'learning_rate': 0.001, 'num_layers': 3}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 5s/step - accuracy: 0.5364 - loss: 0.6815 - val_accuracy: 0.8023 - val_loss: 0.4563\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 5s/step - accuracy: 0.8439 - loss: 0.4032 - val_accuracy: 0.7858 - val_loss: 0.7488\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 5s/step - accuracy: 0.9105 - loss: 0.2517 - val_accuracy: 0.7979 - val_loss: 0.6379\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 884ms/step - accuracy: 0.7966 - loss: 0.4619\n",
            "Test accuracy for {'dropout_rate': 0.7, 'learning_rate': 0.001, 'num_layers': 3}: 0.7932842373847961\n",
            "Training with params: {'dropout_rate': 0.7, 'learning_rate': 0.01, 'num_layers': 1}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - accuracy: 0.4965 - loss: 0.7579 - val_accuracy: 0.4959 - val_loss: 0.6956\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 2s/step - accuracy: 0.5925 - loss: 0.6694 - val_accuracy: 0.7062 - val_loss: 0.5882\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 2s/step - accuracy: 0.8311 - loss: 0.4290 - val_accuracy: 0.7591 - val_loss: 0.5794\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 430ms/step - accuracy: 0.5023 - loss: 0.6947\n",
            "Test accuracy for {'dropout_rate': 0.7, 'learning_rate': 0.01, 'num_layers': 1}: 0.5019662976264954\n",
            "Training with params: {'dropout_rate': 0.7, 'learning_rate': 0.01, 'num_layers': 2}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 4s/step - accuracy: 0.5164 - loss: 0.7878 - val_accuracy: 0.6620 - val_loss: 0.6097\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 4s/step - accuracy: 0.7591 - loss: 0.5301 - val_accuracy: 0.7171 - val_loss: 0.5479\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 4s/step - accuracy: 0.8671 - loss: 0.3369 - val_accuracy: 0.7278 - val_loss: 0.6379\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 665ms/step - accuracy: 0.6665 - loss: 0.6134\n",
            "Test accuracy for {'dropout_rate': 0.7, 'learning_rate': 0.01, 'num_layers': 2}: 0.6681455969810486\n",
            "Training with params: {'dropout_rate': 0.7, 'learning_rate': 0.01, 'num_layers': 3}\n",
            "Epoch 1/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 6s/step - accuracy: 0.5142 - loss: 0.7535 - val_accuracy: 0.4959 - val_loss: 0.6951\n",
            "Epoch 2/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 5s/step - accuracy: 0.5117 - loss: 0.6937 - val_accuracy: 0.4958 - val_loss: 0.6938\n",
            "Epoch 3/5\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 5s/step - accuracy: 0.5003 - loss: 0.7159 - val_accuracy: 0.4967 - val_loss: 0.7052\n",
            "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 926ms/step - accuracy: 0.5023 - loss: 0.6944\n",
            "Test accuracy for {'dropout_rate': 0.7, 'learning_rate': 0.01, 'num_layers': 3}: 0.5019662976264954\n",
            "Best accuracy: 0.8131491541862488\n",
            "Best parameters: {'dropout_rate': 0.3, 'learning_rate': 0.0001, 'num_layers': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "nIWpLxtyJcWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# شناسایی TPU\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print(f\"Running on TPU: {tpu.master()}\")\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "except ValueError:\n",
        "    print(\"TPU not found. Using default strategy.\")\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(f\"Number of replicas: {strategy.num_replicas_in_sync}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq8opnDVXzK_",
        "outputId": "11d0ce26-9683-47ce-fae5-cbbdedb738dc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU: \n",
            "Number of replicas: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تنظیمات اولیه\n",
        "max_len = 200\n",
        "vocab_size = 10000\n",
        "embedding_dim = 128\n",
        "hyperparams = {'dropout_rate': 0.5, 'learning_rate': 0.001, 'num_layers': 1}\n",
        "\n",
        "# تقسیم داده‌ها به آموزش، اعتبارسنجی و تست\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['processed_review'], df['sentiment'], test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# استفاده از Tokenizer برای توکن‌سازی داده‌ها\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# تبدیل متن‌ها به توکن‌های عددی\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# پدینگ توکن‌ها\n",
        "max_len = 200\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_val_pad = pad_sequences(X_val_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "# تبدیل برچسب‌ها به عددی\n",
        "encoder = LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_val = encoder.transform(y_val)\n",
        "y_test = encoder.transform(y_test)\n",
        "\n",
        "# تبدیل به tf.data.Dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_pad, y_train))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_val_pad, y_val))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_pad, y_test))\n",
        "\n",
        "train_dataset = train_dataset.batch(32).shuffle(1000)\n",
        "val_dataset = val_dataset.batch(32)\n",
        "test_dataset = test_dataset.batch(32)\n",
        "\n",
        "# تابع ایجاد مدل\n",
        "def create_model(num_layers=2, learning_rate=0.001, vocab_size=5000, embedding_dim=128, sequence_length=200):\n",
        "    input_layer = Input(shape=(sequence_length,))\n",
        "\n",
        "    # لایه embedding\n",
        "    embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(input_layer)\n",
        "\n",
        "    # لایه‌های LSTM و توجه\n",
        "    x = embedding_layer\n",
        "    for _ in range(num_layers):\n",
        "        x = LSTM(128, return_sequences=True)(x)\n",
        "        attention_layer = Attention()([x, x])  # اعمال توجه\n",
        "        x = Concatenate()([x, attention_layer])\n",
        "\n",
        "    x = Reshape((-1, 256))(x)  # تغییر شکل خروجی\n",
        "    x = LSTM(128)(x)  # LSTM نهایی\n",
        "\n",
        "    # لایه‌های Dropout و Dense\n",
        "    x = Dropout(0.5)(x)\n",
        "    output_layer = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    # ساخت مدل\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    # کامپایل مدل\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# تعریف EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "\n",
        "# ساخت مدل با مکانیزم توجه\n",
        "with strategy.scope():\n",
        "    model = create_model(num_layers=2, learning_rate=0.001)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # آموزش مدل با داده‌ها و اضافه کردن EarlyStopping\n",
        "    history = model.fit(train_dataset, epochs=50, validation_data=val_dataset, callbacks=[early_stopping])\n",
        "\n",
        "    # ارزیابی مدل روی داده‌های تست\n",
        "    test_loss, test_acc = model.evaluate(test_dataset)\n",
        "    print(f\"Test accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gVtn2V0K8LC",
        "outputId": "c89d5bba-3201-45be-dd54-d99eebd9df45"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 54ms/step - accuracy: 0.7837 - loss: 0.4274 - val_accuracy: 0.8790 - val_loss: 0.2958\n",
            "Epoch 2/50\n",
            "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - accuracy: 0.9193 - loss: 0.2146 - val_accuracy: 0.8841 - val_loss: 0.2812\n",
            "Epoch 3/50\n",
            "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - accuracy: 0.9444 - loss: 0.1537 - val_accuracy: 0.8790 - val_loss: 0.3011\n",
            "Epoch 4/50\n",
            "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - accuracy: 0.9565 - loss: 0.1237 - val_accuracy: 0.8841 - val_loss: 0.3310\n",
            "Epoch 5/50\n",
            "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 49ms/step - accuracy: 0.9611 - loss: 0.1042 - val_accuracy: 0.8780 - val_loss: 0.3414\n",
            "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8707 - loss: 0.3137\n",
            "Test accuracy: 0.874193549156189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()  # بررسی معماری مدل"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "GXSGRoe7TS5y",
        "outputId": "780a70af-d5d2-4c57-a82f-fcc0a16c589f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m640,000\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m131,584\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ attention_2 (\u001b[38;5;33mAttention\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
              "│                           │                        │                │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ attention_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m197,120\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ attention_3 (\u001b[38;5;33mAttention\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
              "│                           │                        │                │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ attention_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ concatenate_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m197,120\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m129\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ attention_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
              "│                           │                        │                │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ attention_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ attention_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
              "│                           │                        │                │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ attention_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,497,861\u001b[0m (13.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,497,861</span> (13.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,165,953\u001b[0m (4.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,165,953</span> (4.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,331,908\u001b[0m (8.90 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,331,908</span> (8.90 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ذخیره مدل\n",
        "model_save_path = \"attention_model.h5\"\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved at {model_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxm_1qf_YgGx",
        "outputId": "f13e08cc-a12d-4c88-ac7d-13dda3decaaa"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved at attention_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# بارگذاری مدل ذخیره شده\n",
        "with strategy.scope():\n",
        "    loaded_model = tf.keras.models.load_model(model_save_path, custom_objects={'Attention': Attention})"
      ],
      "metadata": {
        "id": "XyuCX9IzYh07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "893de268-ff79-4e8d-b483-642dca979a06"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ارزیابی مدل\n",
        "test_loss, test_acc = loaded_model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {test_acc}\")\n"
      ],
      "metadata": {
        "id": "_4oGiGdkYlCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40258721-5041-4ee4-85e2-326931e29dee"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.8595 - loss: 0.4094\n",
            "Test Accuracy: 0.8637096881866455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# استخراج وزن‌های توجه با استفاده از استراتژی\n",
        "def extract_attention_weights(model, sample_input, strategy):\n",
        "    with strategy.scope():\n",
        "        attention_layer = [layer for layer in model.layers if isinstance(layer, Attention)][0]\n",
        "        attention_model = Model(inputs=model.input, outputs=attention_layer.output)\n",
        "        return attention_model.predict(sample_input)\n",
        "\n",
        "# دسته‌بندی نمونه‌ها و نمایش نتایج\n",
        "sample_texts = [\"The movie was fantastic!\", \"I didn’t enjoy the film at all.\"]\n",
        "sample_sequences = tokenizer.texts_to_sequences(sample_texts)\n",
        "sample_padded = tf.keras.preprocessing.sequence.pad_sequences(sample_sequences, maxlen=max_len)\n",
        "\n",
        "# استخراج وزن‌های توجه\n",
        "attention_weights = extract_attention_weights(loaded_model, sample_padded, strategy)\n",
        "\n",
        "# پیش‌بینی و نمایش نتایج\n",
        "predictions = loaded_model.predict(sample_padded)\n",
        "\n",
        "for text, pred, weights in zip(sample_texts, predictions, attention_weights):\n",
        "    sentiment = \"Positive\" if pred > 0.5 else \"Negative\"\n",
        "    print(f\"Review: {text}\\nPredicted Sentiment: {sentiment}\\n\")\n",
        "    print(f\"Attention Weights: {weights}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvTK1zSibs-Z",
        "outputId": "5e42f0b1-c232-487a-f04d-f6a696b72f8b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Review: The movie was fantastic!\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Attention Weights: [[-0.00085373 -0.00731761 -0.00643154 ...  0.00071232 -0.00337174\n",
            "  -0.00487617]\n",
            " [-0.00085186 -0.00731593 -0.00643148 ...  0.00071935 -0.00337391\n",
            "  -0.00487675]\n",
            " [-0.00085186 -0.00731593 -0.00643148 ...  0.00071935 -0.00337391\n",
            "  -0.00487675]\n",
            " ...\n",
            " [-0.00085184 -0.0073158  -0.00643126 ...  0.0007193  -0.0033738\n",
            "  -0.00487663]\n",
            " [-0.0008593  -0.00732248 -0.0064304  ...  0.00069128 -0.00336431\n",
            "  -0.00487459]\n",
            " [-0.00223181 -0.00835351 -0.00618002 ... -0.00462935 -0.00159116\n",
            "  -0.00425432]]\n",
            "\n",
            "Review: I didn’t enjoy the film at all.\n",
            "Predicted Sentiment: Positive\n",
            "\n",
            "Attention Weights: [[-0.00050889 -0.00712118 -0.00656279 ...  0.00124743 -0.00405956\n",
            "  -0.00443887]\n",
            " [-0.00050888 -0.00712111 -0.0065626  ...  0.00124739 -0.00405948\n",
            "  -0.00443879]\n",
            " [-0.00050888 -0.00712111 -0.0065626  ...  0.00124739 -0.00405948\n",
            "  -0.00443879]\n",
            " ...\n",
            " [-0.00050886 -0.00712098 -0.00656238 ...  0.00124734 -0.00405937\n",
            "  -0.00443866]\n",
            " [-0.00050342 -0.00713616 -0.00658232 ...  0.00116138 -0.0041106\n",
            "  -0.00436254]\n",
            " [-0.00050556 -0.00713024 -0.00656777 ...  0.00119677 -0.00408169\n",
            "  -0.00439922]]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}